## 如果 Redis 淘汰的数据是脏数据，会发生什么事？

​	对于 Redis 来说，它决定了被淘汰的数据后，会把它们删除。**即使淘汰的数据是脏数据，Redis 也不会把它们写回数据库。**所以，我们在使用 Redis 缓存时，如果数据被修改了，需要在数据修改时就将它写回数据库。**否则，这个脏数据被淘汰时，会被 Redis 删除，而数据库里也没有最新的数据了。**



## 把 Redis 作为只读缓存使用，怎么处理出现的数据不一致？

针对只读缓存来说，我们既可以先删除缓存值再更新数据库，也可以先更新数据库再删除缓存。我的建议是，优先使用先更新数据库再删除缓存的方法，原因主要有两个：

- 先删除缓存值再更新数据库，**有可能导致请求因缓存缺失而访问数据库**，给数据库带来压力；

- 如果业务应用中读取数据库和写缓存的时间不好估算，那么，**延迟双删中的等待时间就不好设置。**

不过，当使用先更新数据库再删除缓存时，也有个地方需要注意，如果业务层要求必须读取一致的数据，那么，我们就需要在更新数据库时，先在 Redis 缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。





## Redis 如何应对并发访问

### redis 主要使用两种方法来进行并发访问控制：

- 加锁是一种常用的方法，在读取数据前，客户端需要先获得锁，否则就无法进行操作。当一个客户端获得锁后，就会一直持有这把锁，直到客户端完成数据更新，才释放这把锁。看上去好像是一种很好的方案，但是，其实这里会有两个问题：一个是，如果加锁操作多，会降低系统的并发访问性能；第二个是，Redis 客户端要加锁时，需要用到分布式锁，而分布式锁实现复杂，需要用额外的存储系统来提供加解锁操作。

- 原子操作是另一种提供并发访问控制的方法。原子操作是指执行过程保持原子性的操作，而且原子操作执行时并不需要再加锁，实现了无锁操作。这样一来，既能保证并发控制，还能减少对系统并发性能的影响。



Redis 提供了两种原子操作的方法来实现并发控制，分别是**单命令操作和 Lua 脚本。**因为原子操作本身不会对太多的资源限制访问，可以维持较高的系统并发性能。



### Redis 使用分布式锁来进行并发控制：

#### 单个 redis 实例

客户端访问redis实例时，可以通过 set -NX -PX 命令来设置锁的锁变量和过时时间，从而来实现并发控制。

#### 多个 redis 实例

由于多个 redis 实例不像单个 redis 实例那样可以直接共享，因此需要使用一个共享存储系统来维护分布式锁，但这样会存在实例发生故障，导致实例无法提供锁操作。因此，Redis 提供了 RedLock 算法，用来实现基于多个实例的分布式锁。





# 脑裂：一次奇怪的数据丢失 

第一步：确认是不是数据同步出现了问题

​	如果是这种情况的数据丢失，我们可以通过比对主从库上的复制进度差值来进行判断，也就是计算 master_repl_offset 和 slave_repl_offset 的差值。如果从库上的 slave_repl_offset 小于原主库的 master_repl_offset，那么，我们就可以认定数据丢失是由数据同步未完成导致的。

第二步：排查客户端的操作日志，发现脑裂现象

​	但是，不同客户端给两个主库发送数据写操作，按道理来说，只会导致新数据会分布在不同的主库上，并不会造成数据丢失。那么，为什么我们的数据仍然丢失了呢？

第三步：发现是原主库假故障导致的脑裂

​	为了验证原主库只是“假故障”，我们也查看了原主库所在服务器的资源使用监控记录。

​	的确，我们看到原主库所在的机器有一段时间的 CPU 利用率突然特别高，这是我们在机器上部署的一个数据采集程序导致的。因为这个程序基本把机器的 CPU 都用满了，导致 Redis 主库无法响应心跳了，在这个期间内，哨兵就把主库判断为客观下线，开始主从切换了。不过，这个数据采集程序很快恢复正常，CPU 的使用率也降下来了。此时，原主库又开始正常服务请求了。

​	**主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行 slave of 命令，和新主库重新进行全量同步。而在全量同步执行的最后阶段，原主库需要清空本地的数据，加载新主库发送的 RDB 文件，这样一来，原主库在主从切换期间保存的新写数据就丢失了。**





# Redis 集群越大越好吗

不是。集群越大，实例之间的通信开销就越大。